# User Trust Score Visualization

This folder contains data visualizations and scripts used for analyzing user trust in AI-generated responses across various thought models. The analysis includes various graphical tools to showcase insights into the perceived trustworthiness of different prompting methods.

## Visualizations Included

This folder includes the following types of visualizations:
- **Barplot:** Displays the comparative trust scores across different models.
- **Boxplot:** Shows distributions, highlighting medians, quartiles, and outliers.
- **Radar Chart:** Compares multiple dimensions of trust across different tasks.
- **Violin Plot:** Provides a detailed view of score distributions, combining aspects of boxplots and density plots.

Each visualization is aimed at providing a nuanced understanding of how different thought models influence user trust across varied tasks.

## Files in the Repository

### Data Files
- `mean_scores.xlsx`: Contains the average values of user trust scores for each model.
- `Users' tasks scores.xlsx`: Detailed score data for individual tasks and models.

### Scripts
- `Barplot.py`: Script to generate the bar chart visualization.
- `Boxplot.py`: Script to generate the boxplot visualization.
- `Radar.py`: Script to generate the radar chart visualization.
- `Violin.py`: Script to generate the violin plot visualization.

### Visualizations
- `Barplot.png`: Bar chart visualization output.
- `Boxplot.png`: Boxplot visualization output.
- `Radar.png`: Radar chart visualization output.
- `Violin.png`: Violin plot visualization output.

## Usage

To recreate the visualizations, ensure you have Python installed along with necessary libraries like matplotlib, seaborn, and pandas. Run the respective `.py` scripts to generate the visualizations from the data files.

